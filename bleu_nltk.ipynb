{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring Machines with BLEU: Applying the BLEU Evaluation Score to Machine Translations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook implements an example of the BLEU score using patent texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu, \n",
    "modified_precision\n",
    "from nltk import word_tokenize, bigrams, trigrams, ngrams\n",
    "import tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect and tokenize texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original language, in Chinese, of patent abstract NLP patent by Alibaba\n",
    "original_txt = \"\"\"本发明公开了一种机器处理及文本纠错方法和装置、计算设备以及存储介质\n",
    "，具体包括错误文本和对应的正确文本的纠错改写对, 以纠错改写对作为训练语料，对机器处理模型\n",
    "进行训练，由此准备好适用于文本纠错的机器处理模型。可以通过从日志中挖掘纠错改写对来对机器\n",
    "处理模型进行训练，使其适于对文本进行纠错。将第一文本输入到机器处理模型中，得到第二文本，\n",
    "即纠错结果文本。另外，还可以使用语言模型或常用词库先判断第一文本是否需要进行纠错。可以使\n",
    "用从日志中挖掘出的训练语料来训练语言模型，也可以通过对日志中的文本进行分词、统计来整理常\n",
    "用词库。由此，使得能够方便地实现文本纠错\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original sentence, in Chinese, from patent NLP abstract by Alibaba\n",
    "original_sentence = \"\"\"可以使用从日志中挖掘出的训练语料来训练语言模型，也可以通过对\n",
    "日志中的文本进行分词、统计来整理常用词库.\"\"\"\n",
    "\n",
    "# human translation #1, via Gengo, of Chinese sentence to English \n",
    "human1_sentence = \"\"\"The training corpus extracted from a log can be used \n",
    "to train the language model, or the common lexicon can be sorted by \n",
    "segmenting and counting text in the log.\"\"\"\n",
    "\n",
    "# human translation #2, via Gengo\n",
    "human2_sentence = \"\"\"It can use the practice language material gathered \n",
    "from the diary or daily journal to train the language model, and it can\n",
    "also initialize the common vocabulary bank through the segmentation and\n",
    "analysis of the diary or daily journal text.\"\"\"\n",
    "\n",
    "# machine translation by Google Translate from Chinese to English\n",
    "google_sentence = \"\"\"The language model can be trained using the training \n",
    "corpus extracted from the log, or the common lexicon can be organized by \n",
    "segmenting and counting the text in the log.\"\"\"\n",
    "\n",
    "# machine translation by WIPO\n",
    "wipo_sentence = \"\"\"The training corpus extracted from the log can be \n",
    "used to train the language model and also, through text segmentation and \n",
    "statistical analysis of text in the log compile a lexicon of commonly \n",
    "used words.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(dictionary):\n",
    "    \"\"\"converts a dictionary of texts to a list of lists of tokens\"\"\"\n",
    "    returned_list = []\n",
    "    for key, value in dictionary.items():\n",
    "        list_val = value.split()\n",
    "        returned_list.append(list_val)\n",
    "    return returned_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_sentences = {'reference_sentence_1': human1_sentence\n",
    "                     ,'reference_sentence_2': human2_sentence\n",
    "                     ,'candidate_sentence_1': google_sentence\n",
    "                     ,'candidate_sentence_2': wipo_sentence}\n",
    "\n",
    "\n",
    "i = tokenize(dict_of_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples of n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'training'),\n",
       " ('training', 'corpus'),\n",
       " ('corpus', 'extracted'),\n",
       " ('extracted', 'from'),\n",
       " ('from', 'a')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this returns a list of bigrams\n",
    "bi_grams = list(bigrams(i[0][0:6]))\n",
    "bi_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'training', 'corpus', 'extracted'),\n",
       " ('training', 'corpus', 'extracted', 'from'),\n",
       " ('corpus', 'extracted', 'from', 'a'),\n",
       " ('extracted', 'from', 'a', 'log'),\n",
       " ('from', 'a', 'log', 'can')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this returns a list of tuples containing 4-grams\n",
    "four_grams = list(ngrams(i[0][0:8], 4))\n",
    "four_grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentence-level scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7666666666666667\n",
      "0.5172413793103449\n",
      "0.35714285714285715\n",
      "0.2222222222222222\n"
     ]
    }
   ],
   "source": [
    "# BLEU-1\n",
    "bleu1mod_google = modified_precision([i[0]], i[2], n=1)\n",
    "print(float(bleu1mod_google))\n",
    "\n",
    "# BLEU-2\n",
    "bleu2mod = modified_precision([i[0]], i[2], n=2)\n",
    "print(float(bleu2mod))\n",
    "\n",
    "# BLEU-3\n",
    "bleu3mod = modified_precision([i[0]], i[2], n=3)\n",
    "print(float(bleu3mod))\n",
    "\n",
    "# BLEU-4\n",
    "bleu4mod = modified_precision([i[0]], i[2], n=4)\n",
    "print(float(bleu4mod))\n",
    "\n",
    "# BLEU-4\n",
    "bleu4mod = modified_precision([i[0]], i[2], n=4)\n",
    "print(float(bleu4mod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7666666666666667\n",
      "0.6297235299224027\n",
      "0.5215911609582645\n",
      "0.4211941439196335\n",
      "0.4211941439196335\n"
     ]
    }
   ],
   "source": [
    "# .42 BLEU-1 score for Google's translation\n",
    "bleu1_google = sentence_bleu([i[0]], i[2], weights=(1.0, 0))\n",
    "print(bleu1_google)\n",
    "\n",
    "# .42 BLEU-2 score for Google's translation\n",
    "bleu2_google = sentence_bleu([i[0]], i[2], weights=(0.5, 0.5))\n",
    "print(bleu2_google)\n",
    "\n",
    "# .42 BLEU-3 score for Google's translation\n",
    "bleu3_google = sentence_bleu([i[0]], i[2], weights=(0.333, 0.333, 0.333))\n",
    "print(bleu3_google)\n",
    "\n",
    "# .42 BLEU-4 score for Google's translation\n",
    "bleu4_google = sentence_bleu([i[0]], i[2], weights=(0.25, 0.25, 0.25, 0.25))\n",
    "print(bleu4_google)\n",
    "\n",
    "# .42 BLEU-4 score for Google's translation\n",
    "bleu4_google = sentence_bleu([i[0]], i[2])\n",
    "print(bleu4_google)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34690864856059794"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .35 BLEU score for WIPO's translation\n",
    "bleu_wipo = sentence_bleu([i[0]], i[3])\n",
    "bleu_wipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4370614964591188"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_google_2refs = sentence_bleu([i[0], i[1]], i[2])\n",
    "bleu_google_2refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38635522321645016"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_wipo_2refs = sentence_bleu([i[0], i[1]], i[3])\n",
    "bleu_wipo_2refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7666666666666667,\n",
       " 0.5172413793103449,\n",
       " 0.35714285714285715,\n",
       " 0.2222222222222222)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "23 / 30, 15 / 29, 10 / 28, 6 / 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47368421052631576"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(23 + 15 + 10 + 6) / (30 + 29 + 28 + 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/29\n"
     ]
    }
   ],
   "source": [
    "bleu2mod = modified_precision([i[0]], i[2], n=2)\n",
    "print(bleu2mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fraction(10, 28)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu3mod = modified_precision([i[0]], i[2], n=3)\n",
    "bleu3mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fraction(6, 27)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu4mod = modified_precision([i[0]], i[2], n=4)\n",
    "bleu4mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('The', 'training', 'corpus', 'extracted'),\n",
       "  ('training', 'corpus', 'extracted', 'from'),\n",
       "  ('corpus', 'extracted', 'from', 'a'),\n",
       "  ('extracted', 'from', 'a', 'log'),\n",
       "  ('from', 'a', 'log', 'can'),\n",
       "  ('a', 'log', 'can', 'be'),\n",
       "  ('log', 'can', 'be', 'used'),\n",
       "  ('can', 'be', 'used', 'to'),\n",
       "  ('be', 'used', 'to', 'train'),\n",
       "  ('used', 'to', 'train', 'the'),\n",
       "  ('to', 'train', 'the', 'language'),\n",
       "  ('train', 'the', 'language', 'model,'),\n",
       "  ('the', 'language', 'model,', 'or'),\n",
       "  ('language', 'model,', 'or', 'the'),\n",
       "  ('model,', 'or', 'the', 'common'),\n",
       "  ('or', 'the', 'common', 'lexicon'),\n",
       "  ('the', 'common', 'lexicon', 'can'),\n",
       "  ('common', 'lexicon', 'can', 'be'),\n",
       "  ('lexicon', 'can', 'be', 'sorted'),\n",
       "  ('can', 'be', 'sorted', 'by'),\n",
       "  ('be', 'sorted', 'by', 'segmenting'),\n",
       "  ('sorted', 'by', 'segmenting', 'and'),\n",
       "  ('by', 'segmenting', 'and', 'counting'),\n",
       "  ('segmenting', 'and', 'counting', 'text'),\n",
       "  ('and', 'counting', 'text', 'in'),\n",
       "  ('counting', 'text', 'in', 'the'),\n",
       "  ('text', 'in', 'the', 'log.')],\n",
       " 27)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_four_grams = list(ngrams(i[0], 4))\n",
    "ref_four_grams, len(four_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('The', 'language', 'model', 'can'),\n",
       "  ('language', 'model', 'can', 'be'),\n",
       "  ('model', 'can', 'be', 'trained'),\n",
       "  ('can', 'be', 'trained', 'using'),\n",
       "  ('be', 'trained', 'using', 'the'),\n",
       "  ('trained', 'using', 'the', 'training'),\n",
       "  ('using', 'the', 'training', 'corpus'),\n",
       "  ('the', 'training', 'corpus', 'extracted'),\n",
       "  ('training', 'corpus', 'extracted', 'from'),\n",
       "  ('corpus', 'extracted', 'from', 'the'),\n",
       "  ('extracted', 'from', 'the', 'log,'),\n",
       "  ('from', 'the', 'log,', 'or'),\n",
       "  ('the', 'log,', 'or', 'the'),\n",
       "  ('log,', 'or', 'the', 'common'),\n",
       "  ('or', 'the', 'common', 'lexicon'),\n",
       "  ('the', 'common', 'lexicon', 'can'),\n",
       "  ('common', 'lexicon', 'can', 'be'),\n",
       "  ('lexicon', 'can', 'be', 'organized'),\n",
       "  ('can', 'be', 'organized', 'by'),\n",
       "  ('be', 'organized', 'by', 'segmenting'),\n",
       "  ('organized', 'by', 'segmenting', 'and'),\n",
       "  ('by', 'segmenting', 'and', 'counting'),\n",
       "  ('segmenting', 'and', 'counting', 'the'),\n",
       "  ('and', 'counting', 'the', 'text'),\n",
       "  ('counting', 'the', 'text', 'in'),\n",
       "  ('the', 'text', 'in', 'the'),\n",
       "  ('text', 'in', 'the', 'log.')],\n",
       " 27)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_four_grams = list(ngrams(i[2], 4))\n",
    "google_four_grams, len(google_four_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't assign to function call (<ipython-input-83-dbc8561fc587>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-83-dbc8561fc587>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    set(ref_four_grams) = set(google_four_grams)\u001b[0m\n\u001b[0m                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't assign to function call\n"
     ]
    }
   ],
   "source": [
    "set(ref_four_grams) = set(google_four_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('by', 'segmenting', 'and', 'counting'),\n",
       " ('common', 'lexicon', 'can', 'be'),\n",
       " ('or', 'the', 'common', 'lexicon'),\n",
       " ('text', 'in', 'the', 'log.'),\n",
       " ('the', 'common', 'lexicon', 'can'),\n",
       " ('training', 'corpus', 'extracted', 'from')}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(google_four_grams) & set(ref_four_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by default, bleu_score calculates a BLEU-4,which i a score for the overlap of up to 4-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculcation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"the geometric mean of the test corpus’ modified precision scores times an exponential brevity penalty factor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn = C∈{Candidates} ∑ n-gram∈C  ∑ Countclip(n-gram) / ∑ Count(n-gram′)\n",
    " C′∈{Candidates} n-gram′ ∈C′"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The strong signal differentiating human (high precision) from machine (low precision) is striking. The difference becomes stronger as we go from un- igram precision to 4-gram precision. It appears that any single n-gram precision score can distinguish between a good translation and a bad translation. To be useful, however, the metric must also reliably distinguish between translations that do not differ so greatly in quality. Furthermore, it must distinguish between two human translations of differing quality. This latter requirement ensures the continued valid- ity of the metric as MT approaches human transla- tion quality.\n",
    "To this end, we obtained a human translation by someone lacking native proficiency in both the source (Chinese) and the target language (English). For comparison, we acquired human translations of the same documents by a native English speaker. We also obtained machine translations by three commer- cial systems. These five “systems” — two humans and three machines — are scored against two refer- ence professional human translations. The average modified n-gram precision results are shown in Fig- ure 2.\n",
    "Each of these n-gram statistics implies the same\n",
    "∑ ∑ Countclip(n-gram) ∑ ∑ Count(n-gram′)\n",
    " C′∈{Candidates} n-gram′ ∈C′"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "score = sentence_bleu(references, candidate)\n",
    "\n",
    "- sentence_bleu accepts a reference sentences as a list of lists of tokens from a sentence.\n",
    "- input reference sentences a list of lists of strings\n",
    "\n",
    "# by default, bleu_score calculates a BLEU-4,which is an the overlap of 4-grams overlaps \n",
    "\n",
    "\n",
    "score = sentence_bleu(references, candidate), 4\n",
    "\n",
    "reference1 = ['It', 'is', 'a', 'guide', 'to', 'action', 'that',\n",
    "               'ensures', 'that', 'the', 'military', 'will', 'forever',\n",
    "               'heed', 'Party', 'commands']\n",
    "\n",
    "reference2 = ['It', 'is', 'the', 'guiding', 'principle', 'which',\n",
    "             'guarantees', 'the', 'military', 'forces', 'always',\n",
    "               'being', 'under', 'the', 'command', 'of', 'the',\n",
    "               'Party']\n",
    "reference3 = ['It', 'is', 'the', 'practical', 'guide', 'for', 'the',\n",
    "              'army', 'always', 'to', 'heed', 'the', 'directions',\n",
    "              'of', 'the', 'party']\n",
    "\n",
    "references = [reference1, reference2, reference3]\n",
    "\n",
    "references\n",
    "\n",
    "hypothesis1 = ['It', 'is', 'a', 'guide', 'to', 'action', 'which',\n",
    "               'ensures', 'that', 'the', 'military', 'always',\n",
    "              'obeys', 'the', 'commands', 'of', 'the', 'party']\n",
    "\n",
    "hypothesis2 = ['It', 'is', 'to', 'insure', 'the', 'troops',\n",
    "             'forever', 'hearing', 'the', 'activity', 'guidebook',\n",
    "             'that', 'party', 'direct']\n",
    "\n",
    "sentence_bleu(references, hypothesis1) # doctest: +ELLIPSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a human translation of the original text, conducted through the company Gengo at a \"standard\" level\n",
    "human_trans = \"\"\"The invention discloses a machine processing and text error correction method and device, a\n",
    "computing device, and a storage medium, specifically comprising corrected and rewritten text pairs of incorrect \n",
    "text and corresponding correct text. The corrected and rewritten text pairs serving as a training corpus to train\n",
    "the machine processing model, thereby preparing a machine processing model suitable for text error correction. \n",
    "Through extraction of corrected and rewritten text pairs from a log, the machine processing model can be trained\n",
    "and thus made fit for text correction by inputting the first text into the machine processing model to get the \n",
    "second text, that is the error correction result text. In addition, the language model or the common lexicon can\n",
    "be used to determine whether the first text needs to be corrected. The training corpus extracted from a log can \n",
    "be used to train the language model, or the common lexicon can be sorted by segmenting and counting text in the \n",
    "log. This is how to easily implement text error correction.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_trans = \"\"\"This invention makes public a machine processing and text error correction method and hardware, computing equipment and storage medium, and specifically pairs error text with the corresponding corrected and modified correct text. It uses this text pair as training material for the machine processing model, and from there prepares the machine processing model that is applied to the text correction. It can train the machine processing model using a diary or daily journal and make it suitable for text correction. The first text version is inputted into the machine processing model to get the second text version, which is the corrected text. Additionally, it can also use a stored language model or common vocabulary bank to determine if the first text version needs correction. It can use the practice language material gathered from the diary or daily journal to train the language model, and it can also initialize the common vocabulary bank through the segmentation and analysis of the diary or daily journal text. Through all this, text correction is conveniently implemented. \n",
    "Translated by: Translator #333872\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_reference = human_trans.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_trans = \"\"\"[\"The invention discloses a machine processing and text error correction method and device, a\n",
    "                    computing device and a storage medium, and particularly comprises an error correction rewriting\n",
    "                    pair of an error text and a corresponding correct text, and an error correction rewriting pair\n",
    "                    as a training corpus, and a machine processing model Training is performed, thereby preparing\n",
    "                    a machine processing model suitable for text correction. The machine processing model can be\n",
    "                    trained to mine the error correction by mining the error correction rewrite pair from the log. \n",
    "                    The first text is input into the machine processing model to obtain a second text, that is, an\n",
    "                    error correction result text. In addition, you can use the language model or common lexicon to\n",
    "                    determine whether the first text needs to be corrected. The language model can be trained using\n",
    "                    the training corpus extracted from the log, or the common lexicon can be organized by segmenting\n",
    "                    and counting the text in the log. Thereby, text correction is facilitated.\"]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wipo_trans = \"\"\"[\"The present invention discloses a machine processing and text correction method and device, \n",
    "computing equipment and a storage medium. Specifically comprising corrected and rewritten text pairs of incorrect \n",
    "text and corresponding correct text, the corrected and rewritten text pairs serving as a training corpus for training\n",
    "a machine processing model, and in this way developing a machine processing model for use in text correction. \n",
    "Through extraction of corrected and rewritten text pairs from a log, the machine processing model can be trained \n",
    "and thus made fit for text correction by inputting a first text into the machine processing model to obtain a second\n",
    "text i.e. a corrected text result. Moreover, a language model or a lexicon of commonly used words can be used to \n",
    "assess whether text needs correction. The training corpus extracted from the log can be used to train the language \n",
    "model and also, through text segmentation and statistical analysis of text in the log compile a lexicon of commonly \n",
    "used words. Thus, text correction can be made easier and more convenient.\"]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_translations:\n",
    "    str_list = []\n",
    "    [list[0].split() for list in lists] \n",
    "    return list of list of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_hypothesis = google_trans.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wipo_hypothesis = wipo_trans.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "references = [human_reference]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_bleu_score = sentence_bleu([human_reference], google_hypothesis)\n",
    "bleu_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wipo_bleu_score = sentence_bleu([human_reference], wipo_hypothesis)\n",
    "wipo_bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_bleu([human_reference], [google_hypothesis])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`corpus_bleu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " corpus_bleu() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - this example hypothesis has zero 3-gram and 4-gram overlaps:\n",
    "sentence_bleu(references, hypothesis2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the `bleu_score` module in the translate module contains ? for applying BLEU\n",
    "\n",
    "the `sentence_bleu` calculates a BLEU score\n",
    "\n",
    "nltk.translate.bleu_score.sentence_bleu\n",
    "\n",
    "- the function accepts as parameters, the reference sentences, the hypothesis sentences, and weights for n-grams\n",
    "\n",
    "- `sentence_bleu` returns a BLEU score\n",
    "\n",
    "- if there is no ngrams overlap for any order of n-grams, BLEU returns the value 0. \n",
    "\n",
    "- the bleu_score submodule of nltk.translate to calculate BLEU scores. \n",
    "- the translate module contains experimental features for machine translation.\n",
    "- the bleu_score submodule contains different implementations of the bleu_score, including both the original algorithm, as well as more recent adaptations of the original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If there is no ngrams overlap for any order of n-grams, BLEU returns the value 0. \n",
    "- This is because the precision for the order of n-grams without overlap is 0, and the geometric mean in the final BLEU score computation multiplies the 0 with the precision of other n-grams. \n",
    "- This results in 0 (independently of the precision of the othe n-gram orders). \n",
    "- The following example has zero 3-gram and 4-gram overlaps:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
